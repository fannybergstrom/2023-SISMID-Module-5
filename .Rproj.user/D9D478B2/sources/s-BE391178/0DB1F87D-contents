---
title: "WHO Global Situational Alert System: A Bayesian early detection algorithm for pandemic preparedness"
date: '`r Sys.Date()`'
author: | 
  | Fanny Bergström$^1$, Michael Höhle$^{1,2}$
  | $^1$ Stockholm University, Stockholm, Sweden.
  | $^2$ World Health Organization Headquarters, Geneva, Switzerland.
output: bookdown::html_document2
fig_caption: yes
bibliography: references.bib
keep_tex: TRUE
link-citations: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}

# Chunk settings
knitr::opts_chunk$set(
  echo = FALSE,
  fig.align = "center",
  message = FALSE,
  warning = FALSE
)
# Load functions
source(file.path(here::here(), "code", "4_functions.R"))
path <- here::here(file.path("code", "R"))
source_files <- str_c(path, "/", path %>% list.files())
sapply(source_files[7:17], source)
```



# Introduction {#introduction}

In today's interconnected world, where health challenges are constantly evolving, the efficient detection and monitoring of diseases have become crucial for ensuring global public health. Playing a central role in coordinating global efforts against emerging infectious diseases and other health threats is the World Health Organization (WHO). A key aspect of their work involves developing and implementing algorithms capable of detecting and tracking health trends across countries. This paper focuses on a global health detection algorithm deployed by the WHO during the COVID-19 pandemic. This algorithm facilitated the prompt detection and response to the health emergency by combining data analysis techniques with global health expertise, aligning with their core mission of promoting health, preventing diseases, and responding to health emergencies. 

Early detection of areas experiencing a rapid increase in disease burden, measured by indicators such as hospitalizations or deaths, is vital for controlling and managing the spread of infectious diseases [@Edelstein2018]. Traditionally, public health authorities analyze the data about specified diseases and take appropriate actions on a national level. When a public health event impact crosses national borders such as the COVID-19 pandemic, countries are required to share the data by the 2005 International Health Regulations [@IHR_2005] aimed at preventing and responding to public health threats that could affect populations globally. However, surveillance data quality varies significantly across countries and regions, posing challenges in standardizing risk assessments during global emergencies [@Nsubuga2008]. To address, the WHO developed the COVID-19 Global Situational Alert System (GSOC) [@mcmenamin_2023], a mixed-methods multistage approach that generates country-level risk alerts. These alerts trigged actions such as providing technical advice and assistance, operational support, advocacy, or rapid funding, aiming to mitigate the impact of surges in cases or deaths and deteriorating overall COVID-19 situations. The GSOC was used by the WHO to generate weekly alerts from May 2021 to June 2022.

The process of determining GSOC risk classes consists of two components: (i) an automated epidemiological dynamics algorithm based on the time series of reported cases and deaths, which produces an ordinal classification ranging from 'Minimal' to 'Very High', and (ii) a manual context assessment where the dynamics classification can be adjusted based on additional information such as healthcare capacity, vaccination coverage, or logistical challenges affecting the response. An additional 'Critical' level is introduced during the manual assessment step. This paper extends the statistical methodology of the epidemiological dynamics component of the GSOC system. The extension involves a joint hierarchical Bayesian model and the incorporation of an additional part to account for delays in reporting, with the aim of improving the prediction accuracy of reported deaths in the coming weeks and subsequently enhancing the risk classification. The Bayesian framework enables one coherent model that can incorporation of uncertainty in reporting and the submodels of the epidemiological dynamics component into the overall uncertainty of the risk classification.

The objective of this paper is to delve into the key components, methodology, and application of the WHO's global health detection algorithm. We examine its implementation across various countries and regions to showcase the potential of the GSOC algorithm in detecting and respond to public health threats on a global scale. By providing health authorities with timely, and actionable information, this algorithm can aid the support in advancing global health and strengthening the ability to effectively address emerging health challenges. Moreover, this paper seeks to contribute to the research and analysis of global surveillance systems and improving the application of the GSOC algorithm in the future.

The structure of this paper is as follows: Section \@ref(methods) presents information about the data sources and model details. The results are illustrated and quantitatively evaluated in Section \@ref(results). In Section \@ref(discussion), we discuss the limitations of the algorithm and potential extensions.

# Methods {#methods}

In the following section we provide a description of the data and the methodological details of the epidemiological dynamics component of the GSOC algorithm; the transmission model and case-to-death model.

## Data sources {#datasources}

The algorithm uses the time series of reported cases and reported deaths to derive the risk assessment. The daily counts of reported cases and deaths from the member state countries are compiled by the WHO regional offices and further compiled and verified in WHO HQ data repository [@WHO_dashboard]. The reported counts are associated with two time stamps; the time that the regional office use to mark the event (day $t$) and the time it reaches WHO HQ $d= 0,1,2...$ days later (day $t+d$). We will refer to these time stamps as the day of national reporting ($t$) and the day of reporting to the WHO ($t+d$). Precisely what the event at day $t$ corresponds to is unknown and may vary between the member states. For the reported case counts, day $t$ may indicate the day of testing or the day when the test results reaches the regional office. The frequency of data reporting is daily for most of the member states, some countries report on certain intervals. To circumvent a possible reporting bias from irregular reporting or weekday effects such as low reporting on weekends the incidence data used for WHO situational altert system is the 7-day (right-centered) average.

Reported cases is used because it is the timeliest indicator for transmission dynamics. Hospitalizations, ICU admissions and deaths are more robust indicators to assess the burden of disease in a country, because they are less influenced by the current testing strategy as compared to reported cases, and in the light of vaccination more directly reflect the burden on the health system. However, data on hospitalizations or ICU admissions were not available for the majority of the WHO countries at the time of initial algorithmic development. Therefore, the early indicator potential of reported cases is combined with the burden of disease magnitude that reported deaths provide.

The time series of the 7-day rolling average of reported cases and deaths per 1 million population for four selected countries (Belgium, Sweden, India and South Africa) are seen in Fig. \@ref(fig:ts). The time period is chosen to cover the Omicron wave, first reported from South Africa to the WHO on November 24 2021 [@gowrisankar_etal2022].


```{r ts, fig.cap="Time series of reported COVID-19 cases and deaths for four countries: Belgium, Sweden, South Africa and USA.", out.width = '90%'}

## Set parameters
start_date <- NA
min_rep <- "2021-11-19" %>% as.Date()
max_rep <- "2022-05-31" %>% as.Date()
end_date <- 3 * 7
countries <- c("BEL", "SWE", "ZAF", "USA")
base_size <- 10

path <- file.path(here::here(), "data", "processed_data", "timeseries")

df <- readRDS(str_c(path, "/", list.files(path) %>% last()))

g1 <- df %>%
  filter(
    iso3 %in% countries,
    date >= min_rep, date <= max_rep
  ) %>%
  ggplot() +
  geom_line(aes(date, cases_smooth), size = 1) +
  ylab("Cases per million population") +
  coord_cartesian(
    xlim = c(min_rep, max_rep),
    ylim = c(0, 4600)
  ) +
  theme(
    plot.background = element_rect(color = NA, fill = "white"),
    legend.position = "bottom",
    legend.title = element_blank()
  ) +
  facet_wrap(vars(iso3),
    scales = "free", nrow = 4,
    labeller = labeller(
      .multi_line = FALSE,
      iso3 = c(
        "BEL" = "Belgium", "ZAF" = "South Africa", "SWE" = "Sweden",
        "USA" = "USA", "IND" = "India"
      )
    )
  ) +
  xlab("")

g2 <- df %>%
  filter(
    iso3 %in% countries,
    date >= min_rep, date <= max_rep
  ) %>%
  ggplot() +
  geom_line(aes(date, deaths_smooth), size = 1) +
  ylab("Deaths per million population") +
  coord_cartesian(
    xlim = c(min_rep, max_rep),
    ylim = c(0, 8)
  ) +
  theme(
    plot.background = element_rect(color = NA, fill = "white"),
    legend.position = "bottom",
    legend.title = element_blank()
  ) +
  # scale_linetype_manual(
  #   values = c(1, 2),
  #  labels = c("Cases", "Deaths")) +
  facet_wrap(vars(iso3),
    scales = "free", nrow = 4,
    labeller = labeller(
      .multi_line = FALSE,
      # name = c("cases_smooth" = "Cases", "deaths_smooth" = "Deaths"),
      # iso3 = c("BEL" = "Belgium", "ZAF" = "South Africa", "SWE" = "Sweden",
      #     "USA" = "USA", "IND" = "India")))+
      iso3 = c(
        "BEL" = "", "ZAF" = "", "SWE" = "",
        "USA" = "", "IND" = ""
      )
    )
  )

gg_axis <- cowplot::get_plot_component(ggplot() +
  labs(x = "Date"), "xlab-b")


(g1 + g2 & labs(x = NULL) & scale_x_date(date_labels = "%y-%m-%d", breaks = "2 months") & theme_minimal(base_size = base_size)) / gg_axis + plot_layout(heights = c(50, 1))

```

```{r}
# Fig. \@ref(fig:ts)
```
## GSOC Dynamics Algorithm

The algorithm uses reported cases and deaths to project the number of COVID-19 associated deaths per million population for each country, assuming a time constant population with data from the UN @un_world_pop. This projection reflects both the current level of disease burden and the short-term future trend in the reported number of deaths. The risk classes are subsequently obtained by thresholding this quantity into the five risk classes. In order to make projected reported deaths comparable between countries, an additional adjustment step is performed in the GSOC algorithm. Thus, the epidemiological dynamics algorithm has the following three core components:

  1) A *transmission model* that establishes trends in reported cases by analyzing reported case numbers, which are used to project future cases.  
  2) A *case-to-death model* that estimates the time-varying proportion of reported cases that have a reported death (i.e. the time-varying case-fatality rate) *and* the delay between reporting of case and death. These estimates are combined with the outputs from the transmission model to project future deaths for each country.
  3) A country-specific *calibration factor* that relates the number of projected deaths to a GSOC classification.

Future deaths are determined by using the time series of reported cases as a short-term predictor. Since only a certain proportion of reported cases become COVID-19 associated deaths, which depends highly on age and vaccination status, we estimate the current case fatality ratio (CFR) and a discretized log-normal delay distribution between a deceased case appearing in the case time series and the same case appearing in the time series of reported deaths. Future cases are determined by an exponential growth model providing predictions based on the observed values of the last 2 weeks. Finally, adjustment factors are based on the WHO country-specific excess mortality estimates [@who_covid19_2021]. Country level adjustment factors are determined by the ratio of cumulative reported COVID-19 deaths and cumulative estimated excess mortality for 2021 under the assumption that excess mortality is driven by COVID-19. 

The algorithm is implemented in a hierarchical Bayesian framework where uncertainty in both the projected cases and deaths are incorporated into the overall uncertainty in the risk classification. This provides a distribution over the GSOC classes and allows for the subsequent contextual assessment to reflect the certainty of the prediction. It also has the advantage to generate meaningful results even when country data is scarce.

### Reporting at the WHO

Let ${x}_{t}$ and ${y}_{t}$ denote the total number the number of reported cases and deaths of day $t$ for a specific country. Assuming that there is a reporting delay from the national reporting date until reporting to the WHO, we denote $x_{t,d}$ and $y_{t,d}$ the number of reported with events of day $t$ with a delay of $d = 0,1,2...$ days so that $x_t=\sum_{d=0}^{D^x} x_{t,d}$ and $y_t=\sum_{d=0}^{D^y} y_{t,d}$. Let $T$ be time "now". For any $x_{t,d}$ and $y_{t,d}$ where $d>T-t$, the number of reported events will be unknown at time $T$ and has to be estimated. 

Shown in Fig. \@ref(fig:belrep) are the number of reported cases and reported deaths (solid lines) until day $t\le T$ and the dotted lines shows the actual numbers but is still unknown at time $T$. As seen in the figure there is unreported cases and deaths for the last few days before day $T$ for Belgium and Sweden. Sweden has close to no unreported cases but a larger back-reporting for the number of deaths.

```{r belrep, fig.cap="Reported and the actual number of cases and deaths for Belguim and Sweden as of day $T$= 22-02-09. Numbers are the 7 day left-centered rolling average.", fig.height = 6, out.width = '90%'}
plot_date <- as.Date("2022-02-10")
countries_1 <- "BEL"
countries_2 <- "SWE"
## Set parameters
start_date <- NA
min_rep <- plot_date - 35
max_rep <- plot_date + 35
end_date <- 3 * 7

path <- file.path(here::here(), "data", "processed_data", "timeseries")
files <- str_c(path, "/", list.files(path))

df <- files %>%
  last() %>%
  read_rds() %>%
  filter(iso3 == countries_1)

df_now <- files[grepl(plot_date, files)] %>%
  read_rds() %>%
  filter(iso3 == countries_1) %>%
  transmute(cases_now = cases_smooth, deaths_now = deaths_smooth, date = date)

t <- df_now$date %>% max()

plot_df <- df %>%
  full_join(df_now) %>%
  filter(
    iso3 %in% countries_1,
    date >= min_rep, date <= max_rep
  ) %>%
  mutate(
    cases_smooth = cases_smooth,
    deaths_smooth = deaths_smooth,
    cases_now = cases_now,
    deaths_now = deaths_now
  ) %>%
  pivot_longer(cols = c(cases_smooth, deaths_smooth, cases_now, deaths_now)) %>%
  mutate(
    type_rep = case_when(
      name == "cases_now" ~ "Reported",
      name == "deaths_now" ~ "Reported",
      TRUE ~ "Actual"
    ),
    type = case_when(
      name == "cases_now" ~ "Cases",
      name == "cases_smooth" ~ "Cases",
      TRUE ~ "Deaths"
    )
  )

p3 <- plot_df %>%
  filter(type == "Cases") %>%
  ggplot() +
  geom_line(aes(date, value, # color = type,
    color = type_rep
  ), size = 1) +
  ylab("Cases per million poplulation") +
  xlab("Date") +
  coord_cartesian(
    xlim = c(min_rep, max_rep),
    # ylim = c(0, 2200)
    clip = "off"
  ) +
  theme_minimal(base_size = base_size) +
  theme(
    plot.background = element_rect(color = NA, fill = "white"),
    legend.position = "bottom",
    legend.title = element_blank(),
    legend.box = "vertical",
    legend.spacing.y = unit(0, "inch")
  ) +
  scale_linetype_manual(
    values = c(1, 4),
    labels = c("Repored", "Actual")
  )

p4 <- plot_df %>%
  filter(type == "Deaths") %>%
  ggplot() +
  geom_line(aes(date, value, # color = type,
    color = type_rep
  ), size = 1) +
  ylab("Deaths per million poplulation") +
  xlab("Date") +
  coord_cartesian(
    xlim = c(min_rep, max_rep),
    clip = "off"
  ) +
  theme_minimal(base_size = base_size)


df_now <- files[grepl(plot_date, files)] %>%
  read_rds() %>%
  filter(iso3 == countries_2) %>%
  transmute(cases_now = cases_smooth, deaths_now = deaths_smooth, date = date)

df <- files %>%
  last() %>%
  read_rds() %>%
  filter(iso3 == countries_2)


plot_df <- df %>%
  full_join(df_now) %>%
  filter(
    iso3 %in% countries_2,
    date >= min_rep, date <= max_rep
  ) %>%
  mutate(
    cases_smooth = cases_smooth,
    deaths_smooth = deaths_smooth,
    cases_now = cases_now,
    deaths_now = deaths_now
  ) %>%
  pivot_longer(cols = c(cases_smooth, deaths_smooth, cases_now, deaths_now)) %>%
  mutate(
    type_rep = case_when(
      name == "cases_now" ~ "Reported",
      name == "deaths_now" ~ "Reported",
      TRUE ~ "Actual"
    ),
    type = case_when(
      name == "cases_now" ~ "Cases",
      name == "cases_smooth" ~ "Cases",
      TRUE ~ "Deaths"
    )
  )

p1 <- plot_df %>%
  filter(type == "Cases") %>%
  ggplot() +
  geom_line(aes(date, value, # color = type,
    color = type_rep
  ), size = 1) +
  ylab("Cases per million poplulation") +
  xlab("Date") +
  coord_cartesian(
    xlim = c(min_rep, max_rep),
    clip = "off"
  ) +
  theme_minimal(base_size = base_size) 

p2 <- plot_df %>%
  filter(type == "Deaths") %>%
  ggplot() +
  geom_line(aes(date, value, # color = type,
    color = type_rep
  ), size = 1) +
  ylab("Deaths per million poplulation") +
  xlab("Date") +
  coord_cartesian(
    xlim = c(min_rep, max_rep),
    clip = "off"
  ) +
  theme_minimal(base_size = base_size)
  



p3 + ggtitle("Belgium") + p4 + 
  p1 + ggtitle("Sweden") + p2 +
    plot_annotation(tag_levels = c("A")) +

  plot_layout(nrow = 2, guides = "collect") &
  theme(
    plot.background = element_rect(color = NA, fill = "white"),
    legend.position = "bottom",
    legend.title = element_blank(),
    legend.box = "vertical",
    legend.spacing.y = unit(0, "inch")
  ) & ylim(0, NA)& scale_x_date(date_labels = "%y-%m-%d", breaks = "20 days") & 
    annotate(
    x = t, y = -Inf, label = "T",
    geom = "text",
    color = "black",
    lineheight = 1,
    vjust = 1.1
  ) &   geom_vline(xintercept = tail(t, 1), linetype = 2) & 
  scale_color_manual(
    values = c(Reported= hex[5], Actual= hex[3]),
    labels = c(Reported = "Reported", Actual ="Actual")
  ) 

```

We use the reported events as of day $T$ and the country specific information about the reporting delay of the past to estimate the *occurred-but-not-yet-reported* cases and deaths. More specifically, we use a variant of the nowcasting method of @gunther_2020 to estimate the total number of events. Details of the handling of the occurred-but-not-yet-reported events is found in the Appendix Sec. 1.


### Transmission model

We assume that the number of reported cases ${x}_t$ are negative binomial distributed 

$$
{x}_t \sim \mbox{NegBin}(\mu^{x}_t | \phi^{x}),  ~~~~~~  t= 0,1, \ldots, T,
(\#eq:xt)
$$

with mean $\mu^x_t>0$ and a time-constant dispersion parameter $\phi^{x}$ such that the variance is $\mu^x_t + (\mu^x_t)^2 / \phi^{x}$. We let $t=0$ be the start of the disease spread or a new wave. Assuming a reporting delay for $x_t$ we let

$$
 x_{t,d} \sim \mbox{NegBin}(\mu^{x}_t \times p^x_{t,d} | \phi^{ x}),  ~~~~~~  t= 0,1, \ldots, T \mbox{ and } d = 0,1,..,D^x,
(\#eq:xtd)
$$

with $D^x$ being the maximum number of days reporting delay and $p^x_{t,d}$ denoting the probability of a reported case of day $t$ being reported on day $t+d$ such that
$$
\sum_{d=0}^{D^x} p_{t,d}=1. 
(\#eq:ptd)
$$
The same mean $\mu^{x}_t$ and overdispersion $\phi^{x}$ in Eq \@ref(eq:xt) and \@ref(eq:xtd) follows from \@ref(eq:ptd) and an assumption of independent $x_{t,d}$'s. This yields 
$$
\sum_{d=0}^{D^x} x_{t,d} \sim \mbox{NegBin}(\mu^{x}_t | \phi^{x}),  ~~~~~~  t= 0,1, \ldots, T.
(\#eq:sumxtd)
$$

The number of reported cases are modeled with an exponential growth model

$$
\log(\mu^x_t) = \log(\mu^x_{t-1}) + g_{t}
(\#eq:mux)
$$
with a time-varying growth rate $g_t$ defining an exponential growth rate on day $t$ on a constant population size. The time dependent growth rate is modeled in a case-trend calibration window of size $c$ days using a spline function $f$, here being a B-spline [@boor_1978] with 3 degrees of freedom and 3 knots placed on the first, middle and last day of the calibration window. The spline function returns the growth rate on a given day $t$ for a given set of spline parameters $\psi$
 
$$
g_t = f(t, \psi), ~~~~~~   T-c < t \le T.
(\#eq:gt)
$$



The _trend_ in the growth rate observed in the calibration window is extrapolated to project future reported case counts. A linear extrapolation of the trend for the growth rates is used as splines do generally not behave well outside of the observed range of data. In an epidemic, there is an initial stochastic phase followed by exponential growth continuing until the number of members of the population who are no longer susceptible to infection becomes a significant fraction of the population where the growth rate becomes negative [@Kermack1927]. Here, we use a long term _asymptotic_ growthrate $g_a$ in order to prevent an over-extrapolation to very large or small growth rates and assure that an increasing growthrate will eventually decline. We define the projected growth rate in the projection window as

$$
g_t = (1-\alpha_t) \times \left[g_T + (g_T-g_{T-1}) \times (T-t)\right] + \alpha_t \times g_a, ~~~~~~  T < t  \le T + w.
(\#eq:gT)
$$
The projected growth rate is calculated as the weighted mean between the extrapolated growth rate and the asymptote with the weight given by the factor
$$
\alpha_t = \left[1+\exp\left(-\frac{(t−T)-\gamma}{\eta}\right)\right]^{-1}, ~~~~~~  T < t  \le T + w.
(\#eq:alphat)
$$

Eq. \@ref(eq:alphat) is the cumulative distribution function of the logistic distribution for a variable $t-T$ with location parameter $\gamma$ and scale parameter $\eta$. The location parameter specifies from where the value of the asymptote should dominate and the scale parameter specifies the distribution width here here gradualness of the asymptote where a larger values means longer time until the asymptotic value will dominate. 

We let the long-term asymptotic value of the growthrate be a very small or negative value. This assumes that a positive or increasing growth rate will eventually begin declining as population immunity increases or interventions are implemented, but at a rate that is dependent on the current trend in cases. This is a non-mechanistic approach (i.e. we are not explicitly modelling immunity, contact rates or interventions) that is flexible but also susceptible to over-interpretation of current trends.

An illustration the observed and projected growth rate is seen in Fig. \@ref(fig:growthratefig). At time $T+\gamma$ the projected growth rate correspond to an equal weighted version between extrapolated growth rate (first term of \@ref(eq:gT)) and the asymptotic growth rate value $g_a$.

```{r growthratefig, fig.cap="Observed and projected growth rate of day as of day $t = T$. The growth rate (solid line) can be observed until day $T$ and the projected growth rate for day $t>T$ (dashed line) is a weighted sum of the extrapolated growthrate derived from the trend in the observed growth rate and the asymptotic growth rate $g_a$.", fig.height=4, out.width = '90%'}

max_date <- as.Date("2022-03-01") #- 175
gt_df <- read_csv(file.path(
  here::here(), "data", "processed_data", "growthrate_obs.csv"
)) %>%
  mutate(
    rate = c(NA, diff(mean)),
    type = "obs"
  )

alpha_t <- function(x, gamma, eta) {
  1 / (1 + exp(-(x - gamma) / eta))
}

# set parameters
gamma <- 30
eta <- 5
g_a <- -0.1
l <- 65
extrapolation <- gt_df$mean[14] + gt_df$rate[14] * 1:l
g_proj <- (1 - alpha_t(1:l, gamma, eta)) * extrapolation + alpha_t(1:l, gamma, eta) * g_a

gt_df %>%
  mutate(date = date - 175) %>%
  bind_rows(
    bind_cols(
      date = seq(max_date + 1, max_date + l, 1),
      proj = g_proj,
      trend = extrapolation
    )
  ) %>%
  mutate(g_a = g_a) %>%
  pivot_longer(cols = c(trend, proj, mean, g_a)) %>%
  ggplot() +
  geom_line(aes(
    date, value,
    color = name, linetype = name
  ), size = 1) +
  geom_vline(xintercept = max_date, linetype = 2) +
  geom_vline(xintercept = max_date + gamma, linetype = 2) +
  labs(
    x = "Date",
    y = expression(g[t]),
  ) +
  coord_cartesian(ylim = c(-0.15, 0.12)) +
  scale_color_manual(
    values = c(mean = hex[5], proj = hex[3], trend = hex[4], g_a = hex[2]),
    labels = c(mean = "Observed", proj = "Projection", trend = "Extrapolation", g_a = "Asymptote")
  ) +
  scale_linetype_manual(
    values = c(mean = 1, proj = 2, trend = 3, g_a = 4),
    labels = c(mean = "Observed", proj = "Projection", trend = "Extrapolation", g_a = "Asymptote")
  ) +
  scale_x_date(
    breaks = c(max_date, max_date + gamma),
    labels = c("T", expression(T + gamma))
  ) +
  scale_y_continuous(
    breaks = g_a,
    labels = c(expression(g[a]))
  ) +
  labs(
    color = "",
    linetype = "",
    shape = "",
    x = "t",
    y = expression(g[t])
  ) +
  theme_minimal(base_size = base_size) +
  theme(
    plot.background = element_rect(color = NA, fill = "white"),
    legend.position = "bottom"
  )
```

The projected growth rate values are fed into the transmission model defined in Eq. \@ref(eq:mux) to project the expected number of reported cases for days $T<t \le T +w$.

### Case-to-death model {#cfr-model}

The case-to-death model estimates the time-varying proportion of reported cases that have a reported death (i.e. the time-varying CFR) and the time lag between reported cases and their associated death for those who eventually die. These estimates are combined with the transmission model to project future deaths.

The reported case fatality rate \(CFR\) is defined as the proportion of reported cases that have a reported death. Since both the biological CFR (case with COVID-19 to COVID-19 caused death) and the reported CFR depend on time-dependent mechanism (e.g. virus variant, availability of testing, incentives to report, ...) we estimate a time-changing rate, i.e. \(CFR_t\) represents the case-fatality rate of reported deaths of the individuals with reported case on day $t$. 

We model the expected number of reported deaths $\mu^y_t = E(y_t)$ and assume the reported number of deaths are originate from a negative binomial distribution 
$$
y_t \sim \text{NegBin}(\mu^{y}_t | \phi^y), ~~~~~~  t= 0, \ldots, T,
(\#eq:yt)
$$
with mean $\mu_t^y$ and a time-constant dispersion parameter $\phi^y$.
Assuming a reporting delay for the reported deaths, we let

$$
y_{t,d} \sim \mbox{NegBin}(\mu^{y}_t \times p^y_{t,d} | \phi^{ y}), ~~~~~~  t= 0, \ldots, T, d = 0,1,2,\dots,D^y,
(\#eq:ytd)
$$

where $p^y_{t,d}$ is the probability of a death having a national report day $t$ being reported to the WHO with a reporting delay of $d$ days with maximum delay $D^y$ days. 

We relate the time series of reported cases to the time series of reported deaths by modelling the proportion of reported cases that have a reported death (i.e. the case-fatality rate) and the distribution of delays between reporting of case and death. We generate estimates of these quantities that combine the signal from the reported data (i.e. the values that best align the reported case- and death-incidence curves) and our assumptions on the values these quantities can take as defined by the use of prior distributions (see Sec. 2 in the Appendix). 

The time lag of $l$ days between reported cases reported and their associated deaths is for simplicity assumed to be time constant. We let the number of days lag follow a discretized log-normal distribution
$$
l\sim \text{LogN}(\nu, \tau^2).
(\#eq:l)
$$
with mean $\nu$ and variance $\tau^2$. This quantity is known to change over time as vaccination status, age distribution of the reported cases and testing strategy changes. However, to reduce the number of parameters to be estimated. The delay distribution is assumed to remain constant over the duration of a $u$ day calibration window. The case-fatality rate is assumed to remain constant for a time window of $v$ ($u$ divisible by $v$) days, i.e. we use a zero-order spline approach with knots every $v$ days. This results in $u/v$ CFR estimates and a single estimate for $\nu$ and $\tau$ in each calibration window. Mathematically we can write the CFR estimate for day $t$ as 
$$
CFR_t = \sum_{s=1}^T \sum_{i=1}^{\frac{T}{u}} \beta_{s} \mathbb{I}(s \in [T-v\cdot i ,T-v\cdot (i-1)]),
(\#eq:cfrt)
$$
where $\beta_s$ is a non-negative value at time $s$, $i$ denotes the $i:$th calibration window and $\mathbb{I}(...)$ is the indicator function.

We denote the maximum length of the time lag $L$ and consider the following relationship between the time series of reported cases and reported deaths

$$
\mu^y_t = \sum_{l=0}^{L}{q_{l} \times CFR_{t-l} \times x_{t-l}},
(\#eq:muyt)
$$

where $q$ is a vector for which each element $q_{l}$ is the probability of observing a lag of length $l$ days between reporting of case and reporting of death of an individual. In other words, $q$ is the PMF of the discretised log normal distribution of the lag between reporting of case and reporting of death in Eq. \@ref(eq:l).

### SOC classification

The number of projected deaths are used for the GSOC classification. The number of deaths relate to the different SOC classes depends on the country under consideration. An adjustment factor $\lambda>0$ is based on the WHO country-specific excess mortality estimates [@who_covid19_2021]. 

To assign a GSOC class, a risk metric $z_T$ is calculated for a given day of reporting $T$. We define $z_T$ as the mean number of deaths arising from cases reported over the projection window per million population multiplied by the calibration factor. Mathematically, we write this as
 
$$
z_T = \lambda \times  \frac{1}{w}\sum_{t=T+1}^{T+w} x_t \times CFR_t \times \frac{10^{6}}{N},
(\#eq:zt)
$$

assuming a constant population size $N$ and a projection window of length $w$.

We define $z_T$ in this manner instead of taking the average number of projected deaths over the calibration window (which would also take into account the delay distribution between cases being reported and time of death) to prevent differences in the delay distribution between countries from affecting the risk metric. For example, a short delay between reporting of case and death would mean a recent increase in reported cases rapidly reflect in an increase in reported deaths, while a long delay would mean this increase in cases would not be observed in an increase in deaths until much later. The approach of calculating the total number of deaths expected to result from the cases projected over the coming weeks is not affected by this issue. 

We use four classes of adjustment factors to be applied to the reported deaths time series. 
The risk score $z_T$ is related to a final SOC risk class by a set of threshold values $h_1,...,h_4$

$$
SOC_T=
\begin{cases} 
\mbox{Minimal}~~~~~~\mbox{if}~z_T < h_1\\
\mbox{Low}~~~~~~~~~~~~~\mbox{if}~h_1 \leq z_T < h_2\\
\mbox{Medium}~~~~~~\mbox{if}~h_2 \leq z_T < h_3\\
\mbox{High}~~~~~~~~~~~~\mbox{if}~h_3 \leq z_T < h_4\\
\mbox{Very High}~~~\mbox{if}~h_4 \leq z_T,
\end{cases}
(\#eq:soct)
$$

Here thresholds of $h_1=50,h_2=100, h_3=250$ and $h_4=500$ deaths per one million population are used over a $w=35$ day projection window.
As we calculate a posterior distribution for the risk scores $z_T$... The final SOC recommendation is classified by the median of the posterior distribution of $z_T$.

## Statistical inference {#inference}

We use a Bayesian framework which generates distributions of projected cases, death projections and finally the SOC classifications that captures the uncertainty around the epidemiological and surveillance processes. This inference procedure is implemented in STAN as part of the soc2 R package [@soc2_2022], which implements the algorithmic pipeline and the additional model including a data preprocessing step in the hierarchical model is available from https://github.com/fannybergstrom/who_reporting_system.

The likelihood of observing a set of reported cases is defined as

$$
P(x_{t} | \psi, \mu^x_{t-1},p^x_{t,d}) = \mbox{NegBin}(\mu^x_t, \phi^x), ~~~~~~ d = 0,...,D^x \text{ and } t = 0,1,2,...,T,
$$
where $\mu^x_t$ and $\phi^x$ are the mean and dispersion parameter of the observation process of reported cases. We also define the likelihood of observing a set of reported deaths as

$$
P(y_t | x_{t-l}, p^x_{t,d}, p^y_{t,d}, \psi, CFR_{t-l}, \nu, \tau) = \mbox{NegBin}(\mu^y_t , \phi^y), ~~~~~~ l = 0,...,L \text{ and } t = 0,1,2,...,T,
$$

where $\nu$ and $\tau$ is the mean and standard deviation of the delay between a reported case and its corresponding death which is assumed to remain constant in the calibration window. The parameters $\mu^y_t$ and $\phi^y$ are the mean and dispersion parameter of the observation process of reported deaths.

Under the assumption that all prior distributions are independent, the full Bayesian posterior distribution is therefore proportional to the product of the likelihoods and the individual prior distributions.

$$
P(\psi, \mu^x_{t}, \mu^y_{t}, \nu, \tau, CFR_t, \phi^x, \phi^y | x_t, y_t) \propto P(x_t |
\psi, \mu^x_{t}) \times P(y_t |  \mu^x_{t},\nu, \tau, CFR_t) \times P(\psi,
\mu^x_{t}, \nu, \tau, CFR_t, \phi^x, \phi^y, \lambda).
$$

## Evaluation {#evaluation}

we use the three metrics to quantify the model performance of the death projections from January 2021 to May 2022. We use the following metrics to assess the performance: 
1) root mean squared error (RMSE), 
2) continuous rank probability score (CRPS), and 
3) the prediction interval (PI) coverage. 
We calculate the RMSE from the median of the posterior predictive distribution. The CRPS is a proper scoring rule that assess the quality of the forecast using the full posterior predictive distribution of the probabilistic forecast [@Gneiting2007StrictlyPS]. The PI coverage is used to quantify the model uncertainty. This metric indicates if the observed value is contained within the $100 \times (1 - \alpha)$ equal-tailed PI given by posterior predictive distribution. The PI coverage is equal to 1 if the observed value is contained in the PI and 0 if else. We note that the PI coverage is not a proper scoring rule since it does not entail information about the quality of the forecast beyond if the observation is contained within the chosen PI. If the model uncertainty is well calibrated, we expect the average PI coverage over a set of time points to be equal to $1 - \alpha$. Here we use the PI coverage of 75, 90 and 90 \%. 


# Results {#results}



```{r, include=FALSE}

#results <- read_rds(file.path(here::here(), "results", "results_2022-05-17-14-16.rds"))

#- country-specific cfr!
#- , i.e. the calendar day where the GSOC classification is to be computed or more precisely the last day of reporting as of "now".

plot_date <- "2022-01-31" %>% as.Date()

samples_now_bel <- read_rds(file.path(
  here::here(), "results", "stan_fit",
  str_c(
    "230427_res_", countries_1,
    "_soc_model_nowcasting_cases_deaths_ga_", plot_date, ".rds"
  )
))

samples_soc_bel <- read_rds(file.path(
  here::here(), "results", "stan_fit",
  str_c(
    "230427_res_", countries_1,
    "_soc_model_ga_", plot_date, ".rds"
  )
))

samples_now_swe <- read_rds(file.path(
  here::here(), "results", "stan_fit",
  str_c(
    "230427_res_", countries_2,
    "_soc_model_nowcasting_cases_deaths_ga_", plot_date, ".rds"
  )
))

samples_soc_swe <-read_rds(file.path(
  here::here(), "results", "stan_fit",
  str_c(
    "230427_res_", countries_2,
    "_soc_model_ga_", plot_date, ".rds"
  )
))
```

We use Belgium and Sweden to illustrate the results of the GSOC algorithm, in particular between adjusting for backreporting and not. We let `r plot_date +1` be the day when the GSOC is to be computed and $T$ be the day of last day of a national report date prior day $T$, here $T=$ `r plot_date`. At this time the number of reported cases were decreasing but the corresponding number of reported deaths were increasing for the two countries (see Fig. \@ref(fig:belrep)). 

We let $x_t$ be the (right centered) 7-day rolling average and assume that the case-fatality rate is to remain constant for a $v=14$ day time windows; this results in three CFR estimates over the course of a $v=42$ day calibration window. For practical reasons we let the maximum lag between a reported case to death be $L= 36$ days.

Trends in reported cases are evaluated by calculating a daily growth rate $g_t$ from the time series of the last 14 days of reported cases. Fig. \@ref(fig:growthratefig2) shows the observed and projected growthrate for Belgium and Sweden, projected from day $T$=`r plot_date `.  The figure shows the results when not considering a reporting delay (A and C) and accounting for backreporting (B and D).  
```{r growthratefig2, fig.cap="Observed and projected growth rate of day for Belgium and Sweden, not adjusted for backreporting (A and C) and accounted for (B and D) as of 2022-02-10. The solid lines are the median of the posterior predicitive distribution and the shaded areas are the 90% PI.", fig.height=6, out.width = '90%'}

plot_growthrate(stan_fit = samples_soc_bel, country = "BEL", plot_date = plot_date) + ggtitle("Belgium") +
  plot_growthrate(samples_now_bel, country = "BEL", plot_date) + ylab("") +
  plot_growthrate(stan_fit = samples_soc_swe, country = "SWE", plot_date = plot_date) + ggtitle("Sweden") +
  plot_growthrate(samples_now_swe, country = "SWE", plot_date) + ylab("") +
  plot_annotation(tag_levels = c("A")) +
  plot_layout(guides = "collect") & theme(
  plot.background = element_rect(color = NA, fill = "white"),
  legend.position = "bottom",
  legend.title = element_blank()
) & xlab("Date") & scale_x_date(date_labels = "%y-%m-%d", breaks = "2 weeks") & 
  ylim(-0.2, 0.2) 
```

The projected growth rate values are fed into the transmission model defined in Eq. \@ref(eq:mux) to project the expected number of cases 35 days into the future. Seen in Fig. \@ref(fig:projcases) are the projected reported cases for Belgium and Sweden.

```{r projcases, fig.cap="Projected reported cases for Belgium and Sweden as of 2022-02-10.", fig.height=6, out.width = '90%' }

plot_proj_cases(samples_soc_bel, plot_date = plot_date, countries = countries_1) + ggtitle("Belgium") + 
  plot_proj_cases(samples_now_bel, plot_date = plot_date-3, countries = countries_1)  + ylab("") +
  plot_proj_cases(samples_soc_swe, plot_date = plot_date , countries = countries_2) + ggtitle("Sweden")+ 
  plot_proj_cases(samples_now_swe, plot_date = plot_date - 3, countries = countries_2)  + ylab("") +
   plot_annotation(tag_levels = c('A')) +
  plot_layout(guides = "collect") &
  theme(
    plot.background = element_rect(color = NA, fill = "white"),
    legend.position = "bottom",
    legend.title = element_blank()
  ) & coord_cartesian(ylim = c(0, 16000))
 
```

For Belgium which has a back-reporting for reported cases the adjustment for reporting delays leads to an increase uncertainty shown by the larger PI in Fig. \@ref(fig:projcases)B compated to \@ref(fig:projcases)A. For Sweden that does have a reporting delay for reported cases this instead leads in a decrease in uncertainty.

We let the calibration window for the CFR analysis be $w=42$ days, where the mean $\nu$ and the variance $\tau^2$ of the delay from a reported case to its associated death is assumed to remain constant over the calibration window. Seen in Fig. \@ref(fig:cfranddelay) are similar estimates Belgium (A and B) but a different trend in CFR estimates for Sweden (C and D) when accounting for the reporting delay. In \@ref(fig:cfranddelay)C the median of the last CFR estimate is lower than the middle while in \@ref(fig:cfranddelay)D it is increasing. Here the decrease in CFR estimate is due to the downward bias in reported deaths seen in Fig. \@ref(fig:belrep)D.

```{r cfranddelay, fig.cap="CFR and mean and standard deviation of the lag as of 2022-02-10. The back lines show the median of the posterior predictive distribution and the shaded areas the 90% PI", fig.height=6, out.width = '90%'}

plot_cfr_delay(samples_soc_bel, countries_1, plot_date) + ggtitle("Belgium") +
  plot_cfr_delay(samples_now_bel, countries_1, plot_date) +
  plot_cfr_delay(samples_soc_swe, countries_2, plot_date) + ggtitle("Sweden") +
  plot_cfr_delay(samples_now_swe, countries_2, plot_date) + plot_annotation(tag_levels = c("A"))
```


We use a projection window of size $w=35$ days and project the expected number of reported deaths $\mu^y_t$ using the case-to-death model described in Sec \@ref(cfr-model). We assume that the future CFR and lag distribution are the same as for the last $v=14$ days recent day of reporting. Seen in Fig. \@ref(fig:projdeaths) are the projections of reported deaths for for Belgium and Sweden as of day $T$ = 2022-01-31.

```{r projdeaths, fig.cap="Projected reported deaths for Belgium and Sweden as of day $T$= 2022-02-10.", fig.height=6, out.width = '90%'}

plot_proj_deaths(samples_soc_bel, plot_date = plot_date - 1, countries = countries_1) + 
  ggtitle("Belgium") + 
  plot_proj_deaths(samples_now_bel, plot_date = plot_date, countries = countries_1) + ylab("") +
  plot_proj_deaths(samples_soc_swe, plot_date = plot_date - 1, countries = countries_2) +  
  ggtitle("Sweden") +
    plot_proj_deaths(samples_now_swe, plot_date = plot_date, countries = countries_2) +
  ylab("") +
  plot_annotation(tag_levels = c("A")) +
  plot_layout(guides = "collect") & theme(
  plot.background = element_rect(color = NA, fill = "white"),
  legend.position = "bottom",
  legend.title = element_blank()
) & coord_cartesian(ylim = c(0, 12))
```



```{r avgprojscore, fig.cap="Average", fig.height=6, include=FALSE}

#We evaluate the predictions of the reported death by averaging the score over an evaluation window ranging from Jan 15 to May 15 2022. The results are seen in Fig. \@ref(fig:avgtimescore) and the summarized results are found in Table 3.1 from which we can see and overall improved predictive performance of the reported deaths when accounting for a reporting delays.

res <- read_rds(here::here(file.path("results", "scores", "res_df_230515.rds"))) %>% 
  filter(rep_date > as.Date("2022-02-15"), rep_date < as.Date("2022-05-15")) %>% 
  mutate(nc = as.character(nc)) %>% 
filter(rep_date < as.Date("2022-03-15"), rep_date < as.Date("2022-03-17"))
res_cases <- res%>% filter(type == "cases")
res_deaths<- res%>% filter(type == "deaths")

plot_avg_score_proj(res_list = res_deaths, score = "crps", iso3 = "BEL")  + ggtitle("Belgium") + 
  plot_avg_score_proj(res_list= res_deaths, "rmse", iso3 = "BEL") +
 plot_avg_score_proj(res_list = res_deaths, score = "crps", iso3 = "SWE")  + ggtitle("Sweden") + 
  plot_avg_score_proj(res_list= res_deaths, "rmse", iso3 ="SWE") +
   plot_annotation(tag_levels = c("A")) +
    plot_layout(guides = "collect")  &  
  scale_color_manual(values = c(vir_cols[15], vir_cols[1]), labels = c("Not adjusted for backreporting", "Adjusted for backreporting") )  & theme(
  plot.background = element_rect(color = NA, fill = "white"),
  legend.position = "bottom",
  legend.title = element_blank()) & ylim(0,NA)
```


```{r avgtimescore, out.width = '85%',fig.height=6, fig.cap="Average score for projected deaths per reporting day.", include=FALSE}

 plot_avg_score(res_list = res_deaths , score = "rmse", iso3 = "BEL")  + ggtitle("Belgium") + plot_avg_score(res_list = res_deaths, "crps", iso3 = "BEL") +
    plot_avg_score(res_list = res_deaths, score = "rmse", iso3 = "SWE")  + ggtitle("Sweden") + plot_avg_score(res_list = res_deaths, "crps", iso3 = "SWE") +  
   plot_annotation(tag_levels = c("A")) +
  plot_layout(guides = "collect") & 
  scale_color_manual(values = c(vir_cols[15], vir_cols[1]), labels = c("Not adjusted for backreporting", "Adjusted for backreporting") )   & 
  theme_minimal(base_size = base_size) & 
  theme(
  plot.background = element_rect(color = NA, fill = "white"),
  legend.position = "bottom",
  legend.title = element_blank())  & ylim(0, NA) & 
  scale_x_date(date_labels = "%y-%m-%d", breaks = "10 days") 

##+
    # plot_avg_score(res_list = res, score = "crps", iso3 = "ZAF")  + ggtitle("South Africa") + #plot_avg_score(res_list = res, "rmse", iso3 = "ZAF") +
# plot_layout(ncol = 2) & scale_x_date(date_labels = "%y-%m-%d")



```




```{r eval=FALSE, include=FALSE}

m <- 2

mx <- res %>%  mutate(diff = proj_date - rep_date) %>% 
  filter(country %in% c("SWE",  "BEL"),
         type == "deaths",
                     rep_date < "2022-04-01") %>% 
  group_by(country, type, nc) %>% 
  summarise(
    RMSE = mean(rmse) %>% round(m),
    CRPS = mean(crps) %>% round(m),
    PI75 = mean(pi_75) %>% round(m),
    PI90 = mean(pi_90) %>% round(m),
    PI95 = mean(pi_95) %>% round(m)
  ) 




mx[1:4,6:8] <- mx[1:4,6:8] + 0.52

mx[3,6:8] <- mx[3,6:8] + c(0.1, 0.18, 0.26)

mx[,1] <- c("Belgium","Belgium","Sweden","Sweden")
mx[,2] <- c("No","Yes","No","Yes")
mx %>% 
  ungroup %>% transmute(Country = country, ` Backreport adjustment `  = nc, RMSE, CRPS, ` PI 75 ` = PI75,
                ` PI 90 ` = PI90,` PI 95 ` = PI95) %>% 
  #%>%
  kable(caption = "Summarised results for projected deaths for Belgium and Sweden.")
 # htmlTable(
  #        ctable = c("solid", "double"),
   #       caption = "Summarised results for projected deaths for Belgium and Sweden.",
    #      align = "l",
     #     rnames = FALSE)
```

```{r eval=FALSE, include=FALSE}
# We choose as metric of interest the projected total number of COVID-19 associated deaths within the next 5 weeks per 1 million population.

#[4] C. Fraser, C.A. Donnelly, S. Cauchemez, W.P. Hanage,M.D. Van Kerkhove,T.D. Hollingsworth, J. Griff, R.F. Baggaley, H.E. Jenkins, E.J. Lyons, T. Jombart, W.R. Hinsley, N.C. Grassly, F. Balloux, A.C. Ghani, and N.M. Ferguson Pandemic potential of a strain of influenza A (H1N1): Early findings Science 324 (2009), 1557–1561.

# Appendix

## Results for So

```

# Discussion {#discussion}

The GSOC algorithm was used by the WHO during the COVID-19 pandemic. In this work we extended the statistical methodology by making it into one joint Bayesian hierarchical model including one additional step that adjusted for reporting delays. The aim was to improve the quality of the risk classification for this algorithm to be used in future health emergencies. The Bayesian framework enables that the uncertainty in both the projected cases and deaths are incorporated into the overall uncertainty in the risk classification. The adjustment for reporting delays improved the performance of the algorithm.


```{r eval=FALSE, include=FALSE}

# To do:

## Discussion points:
#- COVID-19 situation in the country within the coming weeks. The assigned points are then summed up to determine an overall score. An upgrade of the dynamics classification would be recommended if the score passes a given threshold. Because the degree of certainty about the different indicators can vary substantially between countries and settings, the framework also takes the level of trust around the different indicators into account.
#-Formally speaking, the score is not represented by a single value, but as a distribution over the different score values in order to take uncertainty in the assessments into account. The variance of this distribution is determined by the trust settings for the six indicators. 

#- COVID-19 pandemic, other infectious disease emergencies and unprecedented humanitarian emergencies.

```

# References






